# Part 5: Deploy & Test

In this part, you'll deploy the code sandbox agent bundle to a local FireFoundry cluster and test it with curl.

## Prerequisites

Before deploying, ensure you have:

- Minikube running with FireFoundry installed
- `ff-cli` configured with your license
- `kubectl` and `helm` installed

If you haven't set up your local environment yet, see the [Local Development Guide](../../guides/local_dev_setup.md).

## Environment Configuration

### Helm Values

The `helm/values.local.yaml` file (generated by ff-cli) configures your local deployment. Key settings for the code sandbox demo:

```yaml
# helm/values.local.yaml
agentBundle:
  image:
    repository: coder-bundle
    tag: latest
  env:
    - name: CODE_SANDBOX_URL
      value: "http://code-sandbox-service.ff-dev.svc.cluster.local:3000"
    - name: LLM_BROKER_HOST
      value: "firefoundry-core-llm-broker.ff-dev.svc.cluster.local"
    - name: LLM_BROKER_PORT
      value: "50051"
```

### Secrets

Copy the secrets template and fill in your values:

```bash
cp helm/secrets.yaml.template helm/secrets.yaml
```

Edit `helm/secrets.yaml` with your Entity Service and other connection details.

## Build the Docker Image

Build the agent bundle Docker image, targeting the minikube Docker daemon:

```bash
export GITHUB_TOKEN=$NPM_GITHUB_TOKEN
ff-cli ops build coder-bundle --profile minikube
```

This builds the image inside minikube's Docker environment so it's immediately available to Kubernetes pods.

## Deploy to Kubernetes

Install the agent bundle to the cluster:

```bash
ff-cli ops install coder-bundle
```

This creates a Helm release in the `ff-dev` namespace with:
- A deployment running your agent bundle pod
- A service for internal access
- Kong gateway routing for external access

### Verify the Deployment

```bash
# Check pod status
kubectl get pods -n ff-dev -l app.kubernetes.io/instance=coder-bundle

# View logs
kubectl logs -n ff-dev -l app.kubernetes.io/instance=coder-bundle -f
```

You should see:
```
CoderBundleAgentBundle initialized!
CoderBundle server running on port 3000
```

## Port Forward

Set up port forwarding to access the agent bundle through Kong Gateway:

```bash
kubectl port-forward -n ff-control-plane svc/firefoundry-control-kong-proxy 8080:80
```

## Test with curl

### Health Check

```bash
curl http://localhost:8080/agents/ff-dev/coder-bundle/health/ready
```

Expected response:
```json
{ "status": "ready" }
```

### Execute a Code Generation Request

```bash
curl -X POST http://localhost:8080/agents/ff-dev/coder-bundle/api/execute \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Calculate the first 10 Fibonacci numbers and return them as an array"
  }'
```

Expected response:
```json
{
  "success": true,
  "output": {
    "description": "First 10 Fibonacci numbers",
    "result": [0, 1, 1, 2, 3, 5, 8, 13, 21, 34],
    "stdout": ""
  },
  "entity_id": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
}
```

### Try More Prompts

```bash
# Mathematical computation
curl -X POST http://localhost:8080/agents/ff-dev/coder-bundle/api/execute \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Generate all prime numbers less than 100"}'

# String processing
curl -X POST http://localhost:8080/agents/ff-dev/coder-bundle/api/execute \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Count the frequency of each character in the string: Hello World"}'

# Data transformation
curl -X POST http://localhost:8080/agents/ff-dev/coder-bundle/api/execute \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Generate a multiplication table from 1 to 5 as a 2D array"}'
```

## Troubleshooting

### "Bot not found: DemoCoderBot"

The bot module wasn't loaded before the entity tried to look it up. Ensure `CodeTaskEntity.ts` has the side-effect import:
```typescript
import "../bots/DemoCoderBot.js";
```

### "Code block not found"

The LLM didn't produce the expected two-block format. Check:
- The CoderPrompt instructions are clear about the output format
- The model pool name matches a configured LLM broker pool
- The prompt group is wired correctly (system + user messages)

### "Working memory path not found"

The `output_working_memory_paths` in `get_bot_request_args_impl()` must contain a path ending with `.ts` (for TypeScript). Verify:
```typescript
args: {
  output_working_memory_paths: ["code/analysis.ts"],
},
```

### Sandbox connection timeout

The Code Sandbox Service might not be running or reachable. Check:
```bash
kubectl get pods -n ff-dev | grep sandbox
kubectl logs -n ff-dev -l app=code-sandbox-service
```

Verify the `CODE_SANDBOX_URL` environment variable points to the correct service.

### Upgrading After Changes

After making code changes:

```bash
ff-cli ops build coder-bundle --profile minikube
ff-cli ops upgrade coder-bundle
```

## Diagnostic Tools

Use these skills to inspect the running system:

| Tool | Command | Purpose |
|------|---------|---------|
| Entity Graph | `ff-eg-read` | Inspect CodeTaskEntity nodes and their data |
| Working Memory | `ff-wm-read` | View generated code stored in working memory |
| Telemetry | `ff-telemetry-read` | Trace LLM broker requests and bot execution |
| Logs | `kubectl logs -n ff-dev ...` | View pod logs for debugging |

## What You've Built

In this tutorial, you've created a complete agent bundle that:

1. **Accepts natural language prompts** via a REST API endpoint
2. **Generates TypeScript code** using an LLM with structured prompt instructions
3. **Executes code safely** in the Code Sandbox Service
4. **Returns structured results** with execution output
5. **Persists everything** in the entity graph with working memory attachments

### Architecture Recap

```
CoderPrompt          → Instructs the LLM (system message)
DemoCoderBot         → GeneralCoderBot with TypeScript config
CodeTaskEntity       → Entity + BotRunnableEntityMixin
CoderBundleAgentBundle → API endpoint + entity factory
```

### Key Patterns Learned

- **CoderBot hierarchy** -- Abstract base class with template method pattern for code generation
- **GeneralCoderBot** -- Ready-made variant for general-purpose code execution
- **Two-block LLM output** -- JSON metadata + language code block
- **BotRunnableEntityMixin** -- Decoupled entity-bot wiring via registry
- **Working memory** -- Code storage before sandbox execution
- **@ApiEndpoint** -- REST endpoints for external consumers

## Next Steps

- **Add Python support** -- Create a second bot with `language: "python"` and a Python-specific prompt
- **Custom error prompts** -- Override `errorPromptProviders` for better error recovery
- **Build a web UI** -- Use `@firebrandanalytics/ff-sdk` to build a frontend
- **Add code history** -- Create a collection entity to track past executions

---

**Back to:** [Tutorial Index](./README.md)
